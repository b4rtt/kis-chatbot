# Lok√°ln√≠ chatbot nad dokumentac√≠ ‚Äî Next.js + lok√°ln√≠ embeddingy (+ voliteln√Ω lok√°ln√≠ LLM)

Plnƒõ lok√°ln√≠ chatbot nad dokumentac√≠, kter√Ω m≈Ø≈æe bƒõ≈æet na vlastn√≠m notebooku nebo serveru. Um√≠ st√°hnout Markdown z ve≈ôejn√©ho HTTPS √∫lo≈æi≈°tƒõ, vytvo≈ôit lok√°ln√≠ embeddingy (bez Pinecone) a odpov√≠dat pouze z va≈°eho obsahu. Pokud chcete, m≈Ø≈æete generov√°n√≠ prov√°dƒõt lok√°ln√≠m modelem p≈ôes Ollamu nebo levn√Ωm cloudov√Ωm modelem.

## ‚ú® Funkce

- **HTTPS ‚Üí lok√°ln√≠ mirror**: `POST /api/admin/sync` st√°hne `.md` soubory s vyu≈æit√≠m ETag/Last-Modified.
- **Lok√°ln√≠ vektorov√Ω index**: `POST /api/admin/reindex` vytvo≈ô√≠ embeddingy pomoc√≠ `@xenova/transformers` do `docs/index.json`.
- **RAG odpovƒõdi**: `POST /api/ask` kombinuje vektorov√© vyhled√°v√°n√≠ s fallbackem na kl√≠ƒçov√° slova, generuje odpovƒõƒè a p≈ôikl√°d√° citace.
- **Bez extern√≠ DB**: ≈æ√°dn√© Pinecone/Supabase, v≈°echno ≈æije v repozit√°≈ôi.
- **Voliteln√Ω lok√°ln√≠ LLM**: Ollama (`llama3.1:8b-instruct`) pro 100% offline re≈æim.
- **Ochrana admin rout**: v≈°e chr√°nƒõno p≈ôes `x-admin-key`.
- **Vlo≈æiteln√Ω chat widget**: `/embed/widget.js` p≈ôid√° FAB tlaƒç√≠tko a vlo≈æ√≠ chat v iframe (`/embed/panel`) na libovoln√Ω web.

## üß∞ P≈ôedpoklady

- Node.js 20+ a npm
- Pro lok√°ln√≠ embeddingy nen√≠ pot≈ôeba nic dal≈°√≠ho (model se st√°hne p≈ôi prvn√≠m bƒõhu)
- Pro lok√°ln√≠ LLM (voliteln√©): Ollama nainstalovan√° a spu≈°tƒõn√°

## üöÄ Rychl√Ω start

```bash
# 1) Vytvo≈ô projekt
npm create next@latest local-docs-chat --typescript --eslint
cd local-docs-chat

# 2) Nainstaluj z√°vislosti
npm i @xenova/transformers openai

# 3) Vytvo≈ô slo≈æky
mkdir -p docs app/api/admin lib

# 4) P≈ôidej promƒõnn√© prost≈ôed√≠
cat > .env.local <<'ENV'
DOCS_BASE_URLS=https://docs.example.com,https://help.example.com # ve≈ôejn√© HTTPS ko≈ôeny (oddƒõluj ƒç√°rkou)
# DOCS_BASE_URL=https://docs.example.com # voliteln√©, pokud chce≈° zadat jen jeden zdroj
DOCS_DIR=./docs
ADMIN_KEY=super_secret_key

# Voliteln√© pro hybridn√≠ re≈æim (generov√°n√≠ v cloudu):
# OPENAI_API_KEY=sk-...

# Voliteln√© pro lok√°ln√≠ LLM:
# OLLAMA_MODEL=llama3.1:8b-instruct
ENV
```

Vytvo≈ô `next.config.mjs`:

```js
/** @type {import('next').NextConfig} */
const nextConfig = { reactStrictMode: true };
export default nextConfig;
```

Vytvo≈ô `.gitignore`:

```
node_modules
.next
.env*
docs
```

## üìÅ Struktura projektu

```
local-docs-chat/
‚îú‚îÄ app/
‚îÇ  ‚îú‚îÄ page.tsx              # jednoduch√© UI
‚îÇ  ‚îî‚îÄ api/
‚îÇ     ‚îú‚îÄ ask/route.ts       # RAG endpoint
‚îÇ     ‚îî‚îÄ admin/
‚îÇ        ‚îú‚îÄ sync/route.ts   # HTTPS ‚Üí ./docs mirror
‚îÇ        ‚îî‚îÄ reindex/route.ts# embeddingy ‚Üí ./docs/index.json
‚îú‚îÄ lib/
‚îÇ  ‚îú‚îÄ crawler.ts            # vyhled√°n√≠ .md URL
‚îÇ  ‚îú‚îÄ sync.ts               # mirror s ETag/Last-Modified
‚îÇ  ‚îú‚îÄ md.ts                 # dƒõlen√≠ markdownu na bloky
‚îÇ  ‚îú‚îÄ localEmbeddings.ts    # lok√°ln√≠ embeddingy
‚îÇ  ‚îú‚îÄ ingest.ts             # stavba index.json
‚îÇ  ‚îî‚îÄ search.ts             # kosinov√° podobnost/topK
‚îú‚îÄ docs/                    # lok√°ln√≠ mirror + index.json (gitignore)
‚îú‚îÄ .env.local
‚îú‚îÄ next.config.mjs
‚îî‚îÄ package.json
```

## üß± K√≥d (zkop√≠ruj do soubor≈Ø)

### `lib/crawler.ts`

```ts
const RAW_BASES = process.env.DOCS_BASE_URLS ?? process.env.DOCS_BASE_URL ?? "";
const BASES = RAW_BASES.split(/[, \s]+/)
  .map((b) => b.trim())
  .filter(Boolean);
const MAX_PAGES = 200;

if (!BASES.length) {
  throw new Error(
    "Set DOCS_BASE_URL or DOCS_BASE_URLS with at least one HTTPS root."
  );
}

function abs(u: string, base: string) {
  try {
    return new URL(u, base).toString();
  } catch {
    return null;
  }
}

async function listFromManifest(base: string) {
  try {
    const r = await fetch(new URL("index.json", base));
    if (!r.ok) return [];
    const j = await r.json();
    const arr = Array.isArray(j) ? j : Array.isArray(j.urls) ? j.urls : [];
    return arr
      .map((u: string) => abs(u, base))
      .filter(Boolean)
      .filter((u: string) => u.endsWith(".md")) as string[];
  } catch {
    return [];
  }
}

async function crawlBase(base: string) {
  const seen = new Set<string>(),
    out = new Set<string>(),
    q = [base];
  while (q.length && seen.size < MAX_PAGES) {
    const u = q.shift()!;
    if (seen.has(u)) continue;
    seen.add(u);

    let res: Response;
    try {
      res = await fetch(u, { redirect: "follow" });
    } catch {
      continue;
    }
    if (!res.ok) continue;

    const ct = res.headers.get("content-type") || "";
    if (ct.includes("text/markdown") || u.endsWith(".md")) {
      out.add(u);
      continue;
    }
    if (!ct.includes("text/html")) continue;

    const html = await res.text();
    const links = Array.from(html.matchAll(/href="([^"]+)"/g)).map((m) => m[1]);
    for (const l of links) {
      const u2 = abs(l, base);
      if (!u2 || !u2.startsWith(base)) continue;
      if (u2.endsWith(".md")) out.add(u2);
      else if (!u2.includes("#")) q.push(u2);
    }
  }
  return Array.from(out);
}

export async function listMarkdownUrls(): Promise<string[]> {
  const urls = new Set<string>();

  for (const base of BASES) {
    const manifest = await listFromManifest(base);
    if (manifest.length) {
      manifest.forEach((u) => urls.add(u));
      continue;
    }
    const crawled = await crawlBase(base);
    crawled.forEach((u) => urls.add(u));
  }

  if (!urls.size) {
    throw new Error(
      "No .md URLs found. Provide index.json manifests or check DOCS_BASE_URLS."
    );
  }

  return Array.from(urls);
}
```

### `lib/sync.ts`

```ts
import fs from "fs/promises";
import path from "path";
import { listMarkdownUrls } from "./crawler";

const DOCS_DIR = process.env.DOCS_DIR ?? "./docs";
const CACHE_FILE = path.join(DOCS_DIR, ".cache.json");

type Cache = Record<string, { etag?: string; lastModified?: string }>;

async function readCache(): Promise<Cache> {
  try {
    return JSON.parse(await fs.readFile(CACHE_FILE, "utf8"));
  } catch {
    return {};
  }
}
async function writeCache(c: Cache) {
  await fs.mkdir(DOCS_DIR, { recursive: true });
  await fs.writeFile(CACHE_FILE, JSON.stringify(c, null, 2), "utf8");
}
function urlToLocalPath(u: string) {
  const { hostname, pathname } = new URL(u);
  const safe = pathname.replace(/^\/+/, "");
  return path.join(DOCS_DIR, hostname, safe);
}

export async function syncDocs() {
  const urls = await listMarkdownUrls();
  const cache = await readCache();
  const changed: string[] = [];

  for (const u of urls) {
    const headers: Record<string, string> = {};
    const meta = cache[u];
    if (meta?.etag) headers["If-None-Match"] = meta.etag;
    else if (meta?.lastModified)
      headers["If-Modified-Since"] = meta.lastModified;

    const r = await fetch(u, { headers });
    if (r.status === 304) continue;
    if (!r.ok) continue;

    const etag = r.headers.get("etag") || undefined;
    const lastModified = r.headers.get("last-modified") || undefined;
    const text = await r.text();

    const lp = urlToLocalPath(u);
    await fs.mkdir(path.dirname(lp), { recursive: true });
    await fs.writeFile(lp, text, "utf8");

    cache[u] = { etag, lastModified };
    changed.push(lp);
  }

  await writeCache(cache);
  return { ok: true, downloaded: changed.length, changedPaths: changed };
}
```

### `lib/md.ts`

```ts
export function splitMarkdownToChunks(md: string) {
  // Automaticky detekuje typ dokumentu
  const hasHeadings = /\n#{1,6}\s/.test(md);

  // Pro MD s headingy: vƒõt≈°√≠ chunky (800 token≈Ø), headingy d√°vaj√≠ kontext
  // Pro prost√Ω text: men≈°√≠ chunky (300 token≈Ø) pro lep≈°√≠ granularitu
  const maxTokens = hasHeadings ? 800 : 300;
  const overlap = hasHeadings ? 120 : 50;

  // Rozdƒõlen√≠ podle typu dokumentu
  const sections = hasHeadings
    ? md.split(/\n(?=#{1,6}\s)/g) // podle heading≈Ø
    : md.split(/\n\s*\n/g); // podle odstavc≈Ø

  const chunks: string[] = [];
  for (const sec of sections) {
    const trimmed = sec.trim();
    if (!trimmed) continue;

    const words = trimmed.split(/\s+/);
    if (words.length <= maxTokens) {
      chunks.push(trimmed);
      continue;
    }

    // Del≈°√≠ sekce rozdƒõl√≠me s p≈ôekryvem
    for (let i = 0; i < words.length; i += Math.max(1, maxTokens - overlap)) {
      const part = words
        .slice(i, i + maxTokens)
        .join(" ")
        .trim();
      if (part) chunks.push(part);
    }
  }
  return chunks.filter((c) => c.length > 0);
}
```

### `lib/localEmbeddings.ts`

```ts
import { pipeline } from "@xenova/transformers";

const MODEL_ID = process.env.EMB_MODEL_ID || "Xenova/multilingual-e5-small"; // mal√Ω v√≠cejazyƒçn√Ω model

let extractor: any;
async function getExtractor() {
  if (!extractor) extractor = await pipeline("feature-extraction", MODEL_ID);
  return extractor;
}

// mean pooling + normalizace => cosine = dot product
export async function embedTexts(texts: string[]): Promise<number[][]> {
  const model = await getExtractor();
  const out = await model(texts, { pooling: "mean", normalize: true });
  const arr = Array.isArray(out.data) ? out.data : Array.from(out.data);
  return Array.isArray(arr[0]) ? (arr as number[][]) : [arr as number[]];
}
```

### `lib/ingest.ts`

```ts
import fs from "fs/promises";
import path from "path";
import { splitMarkdownToChunks } from "./md";
import { embedTexts } from "./localEmbeddings";

const DOCS_DIR = process.env.DOCS_DIR ?? "./docs";
const INDEX_PATH = path.join(DOCS_DIR, "index.json");

export async function ingestAllMarkdown() {
  const files: string[] = [];
  async function walk(dir: string) {
    const entries = await fs.readdir(dir, { withFileTypes: true });
    for (const e of entries) {
      const p = path.join(dir, e.name);
      if (e.isDirectory()) await walk(p);
      else if (e.isFile() && e.name.endsWith(".md")) files.push(p);
    }
  }
  await walk(DOCS_DIR);

  const all: any[] = [];
  for (const file of files) {
    const raw = await fs.readFile(file, "utf8");
    const rel = path.relative(DOCS_DIR, file);
    const chunks = splitMarkdownToChunks(raw);
    const vectors = await embedTexts(chunks);

    vectors.forEach((v, i) => {
      all.push({
        id: `${rel}#${i}`,
        file: rel,
        idx: i,
        content: chunks[i],
        vector: v,
      });
    });
  }

  await fs.writeFile(
    INDEX_PATH,
    JSON.stringify({ items: all }, null, 2),
    "utf8"
  );
  return {
    ok: true,
    files: files.length,
    chunks: all.length,
    indexPath: INDEX_PATH,
  };
}
```

### `lib/search.ts`

```ts
import { head } from "@vercel/blob";
import fs from "fs/promises";
import path from "path";

const DOCS_DIR = process.env.DOCS_DIR ?? "./docs";
const INDEX_PATH = path.join(DOCS_DIR, "index.json");

export type IndexItem = {
  id: string;
  file: string;
  idx: number;
  content: string;
  vector: number[];
};
let _cache: { items: IndexItem[] } | null = null;

function normalizeText(text: string) {
  return text
    .normalize("NFKD")
    .replace(/[\u0300-\u036f]/g, "")
    .toLowerCase();
}

export async function loadIndex() {
  if (_cache) return _cache;

  let raw: string;
  if (process.env.VERCEL_ENV) {
    const blob = await head("index.json", {
      token: process.env.BLOB_READ_WRITE_TOKEN,
    });
    const response = await fetch(blob.url);
    if (!response.ok) {
      throw new Error(
        `Failed to download index.json from blob storage. Status: ${response.status}`
      );
    }
    raw = await response.text();
  } else {
    raw = await fs.readFile(INDEX_PATH, "utf8");
  }

  _cache = JSON.parse(raw);
  return _cache;
}

export function resetIndexCache() {
  _cache = null;
}

export function topK(qvec: number[], items: IndexItem[], k = 6) {
  const dot = (a: number[], b: number[]) =>
    a.reduce((s, x, i) => s + x * b[i], 0);
  return items
    .map((it) => ({ it, score: dot(qvec, it.vector) }))
    .sort((a, b) => b.score - a.score)
    .slice(0, k)
    .map((s) => ({ ...s.it, score: s.score }));
}

export function keywordSearch(query: string, items: IndexItem[], limit = 3) {
  const tokens = normalizeText(query)
    .split(/\s+/)
    .filter((tok) => tok.length > 2);
  if (!tokens.length) return [];

  return items
    .map((it) => {
      const text = normalizeText(`${it.file}\n${it.content}`);
      const hits = tokens.reduce(
        (count, token) => count + (text.includes(token) ? 1 : 0),
        0
      );
      const coverage = hits / tokens.length;
      return coverage > 0 ? { ...it, score: coverage } : null;
    })
    .filter((entry): entry is IndexItem & { score: number } => Boolean(entry))
    .sort((a, b) => b.score - a.score)
    .slice(0, limit);
}
```

## üåê API trasy

### `app/api/admin/sync/route.ts`

```ts
import { NextRequest, NextResponse } from "next/server";
import { syncDocs } from "@/lib/sync";

export async function POST(req: NextRequest) {
  if (req.headers.get("x-admin-key") !== process.env.ADMIN_KEY)
    return NextResponse.json({ error: "unauthorized" }, { status: 401 });

  const res = await syncDocs();
  return NextResponse.json(res);
}
```

### `app/api/admin/reindex/route.ts`

```ts
import { NextRequest, NextResponse } from "next/server";
import { ingestAllMarkdown } from "@/lib/ingest";
import { syncDocs } from "@/lib/sync";
import { resetIndexCache } from "@/lib/search";

export async function POST(req: NextRequest) {
  if (req.headers.get("x-admin-key") !== process.env.ADMIN_KEY)
    return NextResponse.json({ error: "unauthorized" }, { status: 401 });

  const doSync = new URL(req.url).searchParams.get("sync") === "1";
  if (doSync) await syncDocs();

  const res = await ingestAllMarkdown();
  resetIndexCache();
  return NextResponse.json(res);
}
```

### `app/api/ask/route.ts`

```ts
import { NextRequest, NextResponse } from "next/server";
import { loadIndex, topK, keywordSearch } from "@/lib/search";
import OpenAI from "openai";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });

async function generateLocal(prompt: string) {
  const r = await fetch("http://127.0.0.1:11434/api/generate", {
    method: "POST",
    headers: {"Content-Type":"application/json"},
    body: JSON.stringify({
      model: process.env.OLLAMA_MODEL || "llama3.1:8b-instruct",
      prompt, stream: false,
      options: { temperature: 0.2 },
    }),
  });
  const data = await r.json();
  return data.response as string;
}

export async function POST(req: NextRequest) {
  const { query, k = 6, localOnly = true } = await req.json();
  if (!query) return NextResponse.json({ error: "Chyb√≠ dotaz" }, { status: 400 });

  const { embedTexts } = await import("@/lib/localEmbeddings");
  const [qvec] = await embedTexts([query]);

  const index = await loadIndex();
  const items = index?.items ?? [];
  const vectorPassages = topK(qvec, items, Number(k) || 6);
  const keywordPassages = keywordSearch(query, items, 3);
  const merged = [...vectorPassages];
  for (const candidate of keywordPassages) {
    if (!merged.find((p) => p.id === candidate.id)) merged.push(candidate);
  }
  const passages = merged.slice(0, Number(k) || 6);
  if (!passages.length) {
    return NextResponse.json({ answer: "Kontakt‚Ä¶", citations: [], cost: { ... } });
  }

  const context = passages.map((p,i)=>`[#${i+1}] ${p.file}\n---\n${p.content}`).join("\n\n");
  const sys = "Odpov√≠dej pouze z kontextu‚Ä¶";
  const prompt = `${sys}\n\nQuestion: ${query}\n\nContext:\n${context}`;

  const maxScore = vectorPassages[0]?.score ?? 0;
  if (maxScore < 0.28 && !localOnly && process.env.OPENAI_API_KEY) {
    const chat = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      temperature: 0.2,
      messages: [
        { role: "system", content: sys },
        { role: "user", content: prompt },
      ],
    });
    return NextResponse.json({
      answer: chat.choices[0].message.content,
      citations: passages.map((p,i)=>({ id:i+1, file:p.file, idx:p.idx, score:p.score })),
    });
  }

  const answer = localOnly
    ? await generateLocal(prompt)
    : (await openai.chat.completions.create({
        model: "gpt-4o-mini",
        temperature: 0.2,
        messages: [{ role: "system", content: sys }, { role: "user", content: prompt }],
      })).choices[0].message.content ?? "";

  return NextResponse.json({
    answer,
    citations: passages.map((p,i)=>({ id:i+1, file:p.file, idx:p.idx, score:p.score })),
  });
}
```

## üñ•Ô∏è UI s Markdown renderingem (`app/page.tsx`)

```tsx
"use client";
import { useState } from "react";
import ReactMarkdown from "react-markdown";
import remarkGfm from "remark-gfm";

export default function Page() {
  const [q, setQ] = useState("");
  const [msgs, setMsgs] = useState<{ q: string; a: string; c: any[] }[]>([]);

  async function ask() {
    const r = await fetch("/api/ask", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ query: q, localOnly: false }),
    });
    const data = await r.json();
    setMsgs((m) => [...m, { q, a: data.answer, c: data.citations }]);
    setQ("");
  }

  return (
    <main
      style={{ maxWidth: 800, margin: "40px auto", fontFamily: "system-ui" }}
    >
      <h1>Local Docs Chat</h1>
      <div style={{ display: "flex", gap: 8 }}>
        <input
          value={q}
          onChange={(e) => setQ(e.target.value)}
          onKeyDown={(e) => e.key === "Enter" && ask()}
          placeholder="Ask your docs..."
          style={{ flex: 1, padding: 10, border: "1px solid #ccc" }}
        />
        <button onClick={ask}>Ask</button>
      </div>
      <div style={{ marginTop: 24 }}>
        {msgs.map((m, i) => (
          <div
            key={i}
            style={{ border: "1px solid #eee", padding: 12, margin: "12px 0" }}
          >
            <div>
              <strong>You:</strong> {m.q}
            </div>
            <div style={{ marginTop: 8 }}>
              <strong>Answer:</strong>
              <ReactMarkdown remarkPlugins={[remarkGfm]}>{m.a}</ReactMarkdown>
            </div>
            {m.c?.length ? (
              <div style={{ fontSize: 14, color: "#555", marginTop: 8 }}>
                Sources: {m.c.map((c: any) => `[#${c.id} ${c.file}]`).join(" ")}
              </div>
            ) : null}
          </div>
        ))}
      </div>
    </main>
  );
}
```

**Instalace z√°vislost√≠ pro markdown:**

```bash
npm install react-markdown remark-gfm
```

## ‚ñ∂Ô∏è Spu≈°tƒõn√≠

```bash
npm run dev
```

Synchronizace dokumentace:

```bash
curl -X POST -H "x-admin-key: $ADMIN_KEY" http://localhost:3000/api/admin/sync
```

Reindex (volitelnƒõ i se sync):

```bash
curl -X POST -H "x-admin-key: $ADMIN_KEY" "http://localhost:3000/api/admin/reindex?sync=1"
```

Po reindexaci se cache v pamƒõti automaticky invaliduje, tak≈æe dal≈°√≠ dotazy hned ƒçtou nov√Ω `index.json`.

Dotaz:

```bash
curl -X POST http://localhost:3000/api/ask \
  -H "Content-Type: application/json" \
  -d '{ "query": "How do I reset my password?" }'
```

## üß± Volitelnƒõ: Lok√°ln√≠ LLM p≈ôes Ollamu

1. Nainstaluj Ollamu (macOS/Linux/Win): https://ollama.com
2. St√°hni model:
   ```bash
   ollama pull llama3.1:8b-instruct
   ```
3. Spus≈• server: `ollama serve`
4. V `.env.local` nastav `OLLAMA_MODEL=llama3.1:8b-instruct`

`/api/ask` pou≈æije Ollamu, pokud `localOnly: true` (v√Ωchoz√≠).

## üîÅ Hybridn√≠ re≈æim (lok√°lnƒõ + cloud)

- Embeddingy z≈Øst√°vaj√≠ lok√°ln√≠.
- Generov√°n√≠ m≈Ø≈æe spadnout do cloudu (levn√Ω model) jen kdy≈æ je pot≈ôeba.
- Po≈°li `localOnly: false` v tƒõle `/api/ask`, p≈ô√≠padnƒõ vyu≈æij prah hodnoty relevance (`maxScore`).
- Cena je na mal√©m provozu v ≈ô√°du cent≈Ø za mƒõs√≠c.

## üîí Bezpeƒçnost

- Admin trasy chra≈à p≈ôes `x-admin-key` + ide√°lnƒõ IP whitelist v reverzn√≠ proxy (Caddy/Nginx).
- Slo≈æku `docs/` mƒõj na perzistentn√≠m disku (je v `.gitignore`).

## üõ†Ô∏è Nasazen√≠

- Server s Node 20+ za HTTPS proxy (Caddy/Nginx).
- Dbej na to, aby `docs/` p≈ôe≈æila redeploy (volume/bind mount).
- Systemd (voliteln√©): `npm run build && npm start` pod slu≈æbou.
- Prvn√≠ bƒõh embeddingu st√°hne model `@xenova/transformers` (poƒç√≠tej s t√≠m).

## üß™ Odstra≈àov√°n√≠ pot√≠≈æ√≠

- **≈Ω√°dn√© markdowny**: p≈ôidej manifest `<tv≈Øj_koren>/index.json` pro ka≈æd√Ω z ko≈ôen≈Ø v `DOCS_BASE_URLS`.
- **Prvn√≠ reindex je pomal√Ω**: stahuje se model, pak u≈æ to bƒõ≈æ√≠ rychle.
- **Halucinace**: sni≈æ `k` (t≈ôeba na 4), zp≈ô√≠sni syst√©mov√Ω prompt, kontroluj dƒõlen√≠ na bloky.
- **Lok√°ln√≠ LLM je pomal√©**: zvol men≈°√≠ model (nap≈ô. `mistral:7b`) nebo hybridn√≠ re≈æim.

## üìè Dimenzov√°n√≠

- ~20 stran A4 (~12‚Äì16k token≈Ø) ‚Üí po rozdƒõlen√≠ vyjde 20‚Äì40 chunk≈Ø.
- Lok√°ln√≠ hled√°n√≠ je okam≈æit√©, index m√° stovky kB, nepot≈ôebuje≈° extern√≠ vektorovou DB.

## üîÑ Vylep≈°en√≠ a zmƒõny

### Vylep≈°en√© dƒõlen√≠ textu (2024-11)

- ‚úÖ **Adaptivn√≠ zpracov√°n√≠ dokument≈Ø**: Funkce `splitMarkdownToChunks` automaticky detekuje typ dokumentu:
  - **Markdown s headingy**: Vƒõt≈°√≠ chunky (800 token≈Ø), proto≈æe headingy poskytuj√≠ strukturu a kontext
  - **Prost√Ω text**: Men≈°√≠ chunky (300 token≈Ø) pro lep≈°√≠ granularitu, rozdƒõlen√≠ podle odstavc≈Ø
- ‚úÖ **Univerz√°ln√≠ kompatibilita**: Funguje s klasick√Ωmi MD soubory i prost√Ωmi textov√Ωmi soubory bez form√°tov√°n√≠
- ‚úÖ **Opraven√© embedov√°n√≠ v batch**: Funkce `embedTexts` nyn√≠ spr√°vnƒõ zpracov√°v√° v√≠ce text≈Ø najednou (d≈ô√≠ve vr√°tila jen 1 vektor pro v≈°echny texty)
- ‚úÖ **Pomocn√Ω skript**: P≈ôid√°n `scripts/reindex-docs.ts` pro snadnou reindexaci dokument≈Ø

### Markdown rendering v UI (2024-11)

- ‚úÖ **Automatick√© renderov√°n√≠ markdownu**: Odpovƒõdi se nyn√≠ zobrazuj√≠ s form√°tov√°n√≠m nam√≠sto surov√©ho markdownu
- ‚úÖ **Podpora pro**:
  - **Tuƒçn√Ω text** a _kurz√≠va_
  - [Odkazy](https://example.com)
  - `Inline k√≥d` a bloky k√≥du
  - Seznamy (odr√°≈ækov√© i ƒç√≠slovan√©)
  - > Citace
  - Nadpisy (h1, h2, h3)
  - Tabulky (GitHub Flavored Markdown)
- ‚úÖ **Pƒõkn√© styling**: Markdown elementy jsou stylovan√© v souladu s designem UI (oran≈æov√© akcenty pro odkazy a tuƒçn√Ω text)

## üîå Vlo≈æen√≠ widgetu na jin√© weby

Chat m≈Ø≈æe≈° novƒõ vlo≈æit jako plovouc√≠ FAB tlaƒç√≠tko s rozbalovac√≠m panelem:

```html
<script
  src="https://tvoje-domena.cz/embed/widget.js"
  data-title="Pomoc s dokumentac√≠"
  data-subtitle="Chat, kter√Ω ƒçerp√° jen z na≈°ich zdroj≈Ø"
  data-color="#ff6200"
  data-label="Zeptej se"
  async
></script>
```

- Skript vytvo≈ô√≠ kruhov√© tlaƒç√≠tko v prav√©m (nebo lev√©m) doln√≠m rohu, kter√© otev≈ôe iframe s aplikac√≠ na adrese `/embed/panel`.
- V≈°e bƒõ≈æ√≠ na stejn√© dom√©nƒõ, tak≈æe nen√≠ pot≈ôeba ≈ôe≈°it CORS ani dal≈°√≠ backend zmƒõny.
- Panel je responzivn√≠ (max ≈°√≠≈ôka/v√Ω≈°ka podle viewportu) a zachov√°v√° stejn√© funkce jako hlavn√≠ UI, vƒçetnƒõ citac√≠ a markdown renderingu.

### Dostupn√© atributy

- `data-title` / `data-subtitle` ‚Äì texty v z√°hlav√≠ panelu.
- `data-color` ‚Äì prim√°rn√≠ barva (dotkne se FAB tlaƒç√≠tka i widgetu, z√°rove≈à se prop√≠≈°e do query parametru `accent`).
- `data-label` ‚Äì text ve FAB tlaƒç√≠tku, `data-icon` pro emoji/znak vedle textu.
- `data-position` ‚Äì `"left"` nebo `"right"` (v√Ωchoz√≠).
- `data-width` / `data-height` ‚Äì rozmƒõr panelu (nap≈ô. `data-width="420px"`).
- `data-offset`, p≈ô√≠padnƒõ `data-offset-x` a `data-offset-y` ‚Äì odsazen√≠ od okraj≈Ø str√°nky.
- `data-panel-url` ‚Äì pokud chce≈° naƒç√≠st jinou adresu (nap≈ô. proxy nebo jinou jazykovou mutaci). Mus√≠ j√≠t o URL hostovan√© na stejn√© dom√©nƒõ kv≈Øli p≈ô√≠stupu na API.

Chce≈°-li widget vlo≈æit ruƒçnƒõ do vlastn√≠ komponenty, m≈Ø≈æe≈° pou≈æ√≠t rovnou iframe:

```html
<iframe
  src="https://tvoje-domena.cz/embed/panel?accent=%23ff6200&title=Support%20Bot"
  width="360"
  height="520"
  style="border:0;border-radius:20px;box-shadow:0 30px 60px rgba(5,6,8,0.45)"
></iframe>
```

Interakce m≈Ø≈æe≈° ovl√°dat vlastn√≠m k√≥dem:

- `window.postMessage({ type: "esports-chat-open" }, "*")` ‚Äî otev≈ôe panel.
- `window.postMessage({ type: "esports-chat-close" }, "*")` ‚Äî zav≈ôe panel.
- `window.postMessage({ type: "esports-chat-toggle" }, "*")` ‚Äî p≈ôepne stav.
- Nebo p≈ô√≠mo `window.esportsChatWidget?.open()/close()/toggle()`.

### Jak reindexovat dokumenty

```bash
# Pomoc√≠ skriptu (doporuƒçeno)
npx tsx scripts/reindex-docs.ts

# Nebo pomoc√≠ API
curl -X POST -H "x-admin-key: $ADMIN_KEY" "http://localhost:3000/api/admin/reindex"
```

## ‚úÖ Co m√° agent udƒõlat

- Vytvo≈ôit soubory podle README.
- Nainstalovat z√°vislosti a nastavit `.env.local`.
- Implementovat endpointy a knihovny.
- Spustit dev server a ovƒõ≈ôit:
  - `POST /api/admin/sync` stahuje `.md` soubory
  - `POST /api/admin/reindex` vytv√°≈ô√≠ `docs/index.json`
  - `POST /api/ask` vrac√≠ struƒçn√© odpovƒõdi s citacemi

Hotovo. Zkop√≠ruj tento README do Cursoru, nech Agenta projekt vystavƒõt, dopl≈à `DOCS_BASE_URLS` (nebo `DOCS_BASE_URL`), spus≈• sync ‚Üí reindex ‚Üí ot√°zka a m√°≈° lok√°ln√≠, levn√Ω chatbot nad dokumentac√≠.

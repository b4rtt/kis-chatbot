# LokÃ¡lnÃ­ chatbot nad dokumentacÃ­ â€” Next.js + lokÃ¡lnÃ­ embeddingy (+ volitelnÃ½ lokÃ¡lnÃ­ LLM)

PlnÄ› lokÃ¡lnÃ­ chatbot nad dokumentacÃ­, kterÃ½ mÅ¯Å¾e bÄ›Å¾et na vlastnÃ­m notebooku nebo serveru. UmÃ­ stÃ¡hnout Markdown z veÅ™ejnÃ©ho HTTPS ÃºloÅ¾iÅ¡tÄ›, vytvoÅ™it lokÃ¡lnÃ­ embeddingy (bez Pinecone) a odpovÃ­dat pouze z vaÅ¡eho obsahu. Pokud chcete, mÅ¯Å¾ete generovÃ¡nÃ­ provÃ¡dÄ›t lokÃ¡lnÃ­m modelem pÅ™es Ollamu nebo levnÃ½m cloudovÃ½m modelem.

## âœ¨ Funkce

- **HTTPS â†’ lokÃ¡lnÃ­ mirror**: `POST /api/admin/sync` stÃ¡hne `.md` soubory s vyuÅ¾itÃ­m ETag/Last-Modified.
- **LokÃ¡lnÃ­ vektorovÃ½ index**: `POST /api/admin/reindex` vytvoÅ™Ã­ embeddingy pomocÃ­ `@xenova/transformers` do `docs/index.json`.
- **RAG odpovÄ›di**: `POST /api/ask` kombinuje vektorovÃ© vyhledÃ¡vÃ¡nÃ­ s fallbackem na klÃ­ÄovÃ¡ slova, generuje odpovÄ›Ä a pÅ™iklÃ¡dÃ¡ citace.
- **Bez externÃ­ DB**: Å¾Ã¡dnÃ© Pinecone/Supabase, vÅ¡echno Å¾ije v repozitÃ¡Å™i.
- **VolitelnÃ½ lokÃ¡lnÃ­ LLM**: Ollama (`llama3.1:8b-instruct`) pro 100% offline reÅ¾im.
- **Ochrana admin rout**: vÅ¡e chrÃ¡nÄ›no pÅ™es `x-admin-key`.
- **VloÅ¾itelnÃ½ chat widget**: `/embed/widget.js` pÅ™idÃ¡ FAB tlaÄÃ­tko a vloÅ¾Ã­ chat v iframe (`/embed/panel`) na libovolnÃ½ web.

## ğŸ§° PÅ™edpoklady

- Node.js 20+ a npm
- Pro lokÃ¡lnÃ­ embeddingy nenÃ­ potÅ™eba nic dalÅ¡Ã­ho (model se stÃ¡hne pÅ™i prvnÃ­m bÄ›hu)
- Pro lokÃ¡lnÃ­ LLM (volitelnÃ©): Ollama nainstalovanÃ¡ a spuÅ¡tÄ›nÃ¡

## ğŸš€ RychlÃ½ start

```bash
# 1) VytvoÅ™ projekt
npm create next@latest local-docs-chat --typescript --eslint
cd local-docs-chat

# 2) Nainstaluj zÃ¡vislosti
npm i @xenova/transformers openai

# 3) VytvoÅ™ sloÅ¾ky
mkdir -p docs app/api/admin lib

# 4) PÅ™idej promÄ›nnÃ© prostÅ™edÃ­
cat > .env.local <<'ENV'
DOCS_BASE_URLS=https://docs.example.com,https://help.example.com # veÅ™ejnÃ© HTTPS koÅ™eny (oddÄ›luj ÄÃ¡rkou)
# DOCS_BASE_URL=https://docs.example.com # volitelnÃ©, pokud chceÅ¡ zadat jen jeden zdroj
DOCS_DIR=./docs
ADMIN_KEY=super_secret_key

# VeÅ™ejnÃ© API
PUBLIC_API_KEY=your_secret_key_here
RATE_LIMIT_MAX_REQUESTS=20 # poÄet poÅ¾adavkÅ¯ za 10 minut (volitelnÃ©, vÃ½chozÃ­: 20)

# VolitelnÃ© pro hybridnÃ­ reÅ¾im (generovÃ¡nÃ­ v cloudu):
# OPENAI_API_KEY=sk-...

# VolitelnÃ© pro lokÃ¡lnÃ­ LLM:
# OLLAMA_MODEL=llama3.1:8b-instruct
ENV
```

VytvoÅ™ `next.config.mjs`:

```js
/** @type {import('next').NextConfig} */
const nextConfig = { reactStrictMode: true };
export default nextConfig;
```

VytvoÅ™ `.gitignore`:

```
node_modules
.next
.env*
docs
```

## ğŸ“ Struktura projektu

```
local-docs-chat/
â”œâ”€ app/
â”‚  â”œâ”€ page.tsx              # jednoduchÃ© UI
â”‚  â””â”€ api/
â”‚     â”œâ”€ ask/route.ts       # RAG endpoint
â”‚     â””â”€ admin/
â”‚        â”œâ”€ sync/route.ts   # HTTPS â†’ ./docs mirror
â”‚        â””â”€ reindex/route.ts# embeddingy â†’ ./docs/index.json
â”œâ”€ lib/
â”‚  â”œâ”€ crawler.ts            # vyhledÃ¡nÃ­ .md URL
â”‚  â”œâ”€ sync.ts               # mirror s ETag/Last-Modified
â”‚  â”œâ”€ md.ts                 # dÄ›lenÃ­ markdownu na bloky
â”‚  â”œâ”€ localEmbeddings.ts    # lokÃ¡lnÃ­ embeddingy
â”‚  â”œâ”€ ingest.ts             # stavba index.json
â”‚  â””â”€ search.ts             # kosinovÃ¡ podobnost/topK
â”œâ”€ docs/                    # lokÃ¡lnÃ­ mirror + index.json (gitignore)
â”œâ”€ .env.local
â”œâ”€ next.config.mjs
â””â”€ package.json
```

## ğŸ§± KÃ³d (zkopÃ­ruj do souborÅ¯)

### `lib/crawler.ts`

```ts
const RAW_BASES = process.env.DOCS_BASE_URLS ?? process.env.DOCS_BASE_URL ?? "";
const BASES = RAW_BASES.split(/[, \s]+/)
  .map((b) => b.trim())
  .filter(Boolean);
const MAX_PAGES = 200;

if (!BASES.length) {
  throw new Error(
    "Set DOCS_BASE_URL or DOCS_BASE_URLS with at least one HTTPS root."
  );
}

function abs(u: string, base: string) {
  try {
    return new URL(u, base).toString();
  } catch {
    return null;
  }
}

async function listFromManifest(base: string) {
  try {
    const r = await fetch(new URL("index.json", base));
    if (!r.ok) return [];
    const j = await r.json();
    const arr = Array.isArray(j) ? j : Array.isArray(j.urls) ? j.urls : [];
    return arr
      .map((u: string) => abs(u, base))
      .filter(Boolean)
      .filter((u: string) => u.endsWith(".md")) as string[];
  } catch {
    return [];
  }
}

async function crawlBase(base: string) {
  const seen = new Set<string>(),
    out = new Set<string>(),
    q = [base];
  while (q.length && seen.size < MAX_PAGES) {
    const u = q.shift()!;
    if (seen.has(u)) continue;
    seen.add(u);

    let res: Response;
    try {
      res = await fetch(u, { redirect: "follow" });
    } catch {
      continue;
    }
    if (!res.ok) continue;

    const ct = res.headers.get("content-type") || "";
    if (ct.includes("text/markdown") || u.endsWith(".md")) {
      out.add(u);
      continue;
    }
    if (!ct.includes("text/html")) continue;

    const html = await res.text();
    const links = Array.from(html.matchAll(/href="([^"]+)"/g)).map((m) => m[1]);
    for (const l of links) {
      const u2 = abs(l, base);
      if (!u2 || !u2.startsWith(base)) continue;
      if (u2.endsWith(".md")) out.add(u2);
      else if (!u2.includes("#")) q.push(u2);
    }
  }
  return Array.from(out);
}

export async function listMarkdownUrls(): Promise<string[]> {
  const urls = new Set<string>();

  for (const base of BASES) {
    const manifest = await listFromManifest(base);
    if (manifest.length) {
      manifest.forEach((u) => urls.add(u));
      continue;
    }
    const crawled = await crawlBase(base);
    crawled.forEach((u) => urls.add(u));
  }

  if (!urls.size) {
    throw new Error(
      "No .md URLs found. Provide index.json manifests or check DOCS_BASE_URLS."
    );
  }

  return Array.from(urls);
}
```

### `lib/sync.ts`

```ts
import fs from "fs/promises";
import path from "path";
import { listMarkdownUrls } from "./crawler";

const DOCS_DIR = process.env.DOCS_DIR ?? "./docs";
const CACHE_FILE = path.join(DOCS_DIR, ".cache.json");

type Cache = Record<string, { etag?: string; lastModified?: string }>;

async function readCache(): Promise<Cache> {
  try {
    return JSON.parse(await fs.readFile(CACHE_FILE, "utf8"));
  } catch {
    return {};
  }
}
async function writeCache(c: Cache) {
  await fs.mkdir(DOCS_DIR, { recursive: true });
  await fs.writeFile(CACHE_FILE, JSON.stringify(c, null, 2), "utf8");
}
function urlToLocalPath(u: string) {
  const { hostname, pathname } = new URL(u);
  const safe = pathname.replace(/^\/+/, "");
  return path.join(DOCS_DIR, hostname, safe);
}

export async function syncDocs() {
  const urls = await listMarkdownUrls();
  const cache = await readCache();
  const changed: string[] = [];

  for (const u of urls) {
    const headers: Record<string, string> = {};
    const meta = cache[u];
    if (meta?.etag) headers["If-None-Match"] = meta.etag;
    else if (meta?.lastModified)
      headers["If-Modified-Since"] = meta.lastModified;

    const r = await fetch(u, { headers });
    if (r.status === 304) continue;
    if (!r.ok) continue;

    const etag = r.headers.get("etag") || undefined;
    const lastModified = r.headers.get("last-modified") || undefined;
    const text = await r.text();

    const lp = urlToLocalPath(u);
    await fs.mkdir(path.dirname(lp), { recursive: true });
    await fs.writeFile(lp, text, "utf8");

    cache[u] = { etag, lastModified };
    changed.push(lp);
  }

  await writeCache(cache);
  return { ok: true, downloaded: changed.length, changedPaths: changed };
}
```

### `lib/md.ts`

```ts
export function splitMarkdownToChunks(md: string) {
  // Automaticky detekuje typ dokumentu
  const hasHeadings = /\n#{1,6}\s/.test(md);

  // Pro MD s headingy: vÄ›tÅ¡Ã­ chunky (800 tokenÅ¯), headingy dÃ¡vajÃ­ kontext
  // Pro prostÃ½ text: menÅ¡Ã­ chunky (300 tokenÅ¯) pro lepÅ¡Ã­ granularitu
  const maxTokens = hasHeadings ? 800 : 300;
  const overlap = hasHeadings ? 120 : 50;

  // RozdÄ›lenÃ­ podle typu dokumentu
  const sections = hasHeadings
    ? md.split(/\n(?=#{1,6}\s)/g) // podle headingÅ¯
    : md.split(/\n\s*\n/g); // podle odstavcÅ¯

  const chunks: string[] = [];
  for (const sec of sections) {
    const trimmed = sec.trim();
    if (!trimmed) continue;

    const words = trimmed.split(/\s+/);
    if (words.length <= maxTokens) {
      chunks.push(trimmed);
      continue;
    }

    // DelÅ¡Ã­ sekce rozdÄ›lÃ­me s pÅ™ekryvem
    for (let i = 0; i < words.length; i += Math.max(1, maxTokens - overlap)) {
      const part = words
        .slice(i, i + maxTokens)
        .join(" ")
        .trim();
      if (part) chunks.push(part);
    }
  }
  return chunks.filter((c) => c.length > 0);
}
```

### `lib/localEmbeddings.ts`

```ts
import { pipeline } from "@xenova/transformers";

const MODEL_ID = process.env.EMB_MODEL_ID || "Xenova/multilingual-e5-small"; // malÃ½ vÃ­cejazyÄnÃ½ model

let extractor: any;
async function getExtractor() {
  if (!extractor) extractor = await pipeline("feature-extraction", MODEL_ID);
  return extractor;
}

// mean pooling + normalizace => cosine = dot product
export async function embedTexts(texts: string[]): Promise<number[][]> {
  const model = await getExtractor();
  const out = await model(texts, { pooling: "mean", normalize: true });
  const arr = Array.isArray(out.data) ? out.data : Array.from(out.data);
  return Array.isArray(arr[0]) ? (arr as number[][]) : [arr as number[]];
}
```

### `lib/ingest.ts`

```ts
import fs from "fs/promises";
import path from "path";
import { splitMarkdownToChunks } from "./md";
import { embedTexts } from "./localEmbeddings";

const DOCS_DIR = process.env.DOCS_DIR ?? "./docs";
const INDEX_PATH = path.join(DOCS_DIR, "index.json");

export async function ingestAllMarkdown() {
  const files: string[] = [];
  async function walk(dir: string) {
    const entries = await fs.readdir(dir, { withFileTypes: true });
    for (const e of entries) {
      const p = path.join(dir, e.name);
      if (e.isDirectory()) await walk(p);
      else if (e.isFile() && e.name.endsWith(".md")) files.push(p);
    }
  }
  await walk(DOCS_DIR);

  const all: any[] = [];
  for (const file of files) {
    const raw = await fs.readFile(file, "utf8");
    const rel = path.relative(DOCS_DIR, file);
    const chunks = splitMarkdownToChunks(raw);
    const vectors = await embedTexts(chunks);

    vectors.forEach((v, i) => {
      all.push({
        id: `${rel}#${i}`,
        file: rel,
        idx: i,
        content: chunks[i],
        vector: v,
      });
    });
  }

  await fs.writeFile(
    INDEX_PATH,
    JSON.stringify({ items: all }, null, 2),
    "utf8"
  );
  return {
    ok: true,
    files: files.length,
    chunks: all.length,
    indexPath: INDEX_PATH,
  };
}
```

### `lib/search.ts`

```ts
import { head } from "@vercel/blob";
import fs from "fs/promises";
import path from "path";

const DOCS_DIR = process.env.DOCS_DIR ?? "./docs";
const INDEX_PATH = path.join(DOCS_DIR, "index.json");

export type IndexItem = {
  id: string;
  file: string;
  idx: number;
  content: string;
  vector: number[];
};
let _cache: { items: IndexItem[] } | null = null;

function normalizeText(text: string) {
  return text
    .normalize("NFKD")
    .replace(/[\u0300-\u036f]/g, "")
    .toLowerCase();
}

export async function loadIndex() {
  if (_cache) return _cache;

  let raw: string;
  if (process.env.VERCEL_ENV) {
    const blob = await head("index.json", {
      token: process.env.BLOB_READ_WRITE_TOKEN,
    });
    const response = await fetch(blob.url);
    if (!response.ok) {
      throw new Error(
        `Failed to download index.json from blob storage. Status: ${response.status}`
      );
    }
    raw = await response.text();
  } else {
    raw = await fs.readFile(INDEX_PATH, "utf8");
  }

  _cache = JSON.parse(raw);
  return _cache;
}

export function resetIndexCache() {
  _cache = null;
}

export function topK(qvec: number[], items: IndexItem[], k = 6) {
  const dot = (a: number[], b: number[]) =>
    a.reduce((s, x, i) => s + x * b[i], 0);
  return items
    .map((it) => ({ it, score: dot(qvec, it.vector) }))
    .sort((a, b) => b.score - a.score)
    .slice(0, k)
    .map((s) => ({ ...s.it, score: s.score }));
}

export function keywordSearch(query: string, items: IndexItem[], limit = 3) {
  const tokens = normalizeText(query)
    .split(/\s+/)
    .filter((tok) => tok.length > 2);
  if (!tokens.length) return [];

  return items
    .map((it) => {
      const text = normalizeText(`${it.file}\n${it.content}`);
      const hits = tokens.reduce(
        (count, token) => count + (text.includes(token) ? 1 : 0),
        0
      );
      const coverage = hits / tokens.length;
      return coverage > 0 ? { ...it, score: coverage } : null;
    })
    .filter((entry): entry is IndexItem & { score: number } => Boolean(entry))
    .sort((a, b) => b.score - a.score)
    .slice(0, limit);
}
```

## ğŸŒ API trasy

### `app/api/admin/sync/route.ts`

```ts
import { NextRequest, NextResponse } from "next/server";
import { syncDocs } from "@/lib/sync";

export async function POST(req: NextRequest) {
  if (req.headers.get("x-admin-key") !== process.env.ADMIN_KEY)
    return NextResponse.json({ error: "unauthorized" }, { status: 401 });

  const res = await syncDocs();
  return NextResponse.json(res);
}
```

### `app/api/admin/reindex/route.ts`

```ts
import { NextRequest, NextResponse } from "next/server";
import { ingestAllMarkdown } from "@/lib/ingest";
import { syncDocs } from "@/lib/sync";
import { resetIndexCache } from "@/lib/search";

export async function POST(req: NextRequest) {
  if (req.headers.get("x-admin-key") !== process.env.ADMIN_KEY)
    return NextResponse.json({ error: "unauthorized" }, { status: 401 });

  const doSync = new URL(req.url).searchParams.get("sync") === "1";
  if (doSync) await syncDocs();

  const res = await ingestAllMarkdown();
  resetIndexCache();
  return NextResponse.json(res);
}
```

### `app/api/ask/route.ts`

```ts
import { NextRequest, NextResponse } from "next/server";
import { loadIndex, topK, keywordSearch } from "@/lib/search";
import OpenAI from "openai";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY! });

async function generateLocal(prompt: string) {
  const r = await fetch("http://127.0.0.1:11434/api/generate", {
    method: "POST",
    headers: {"Content-Type":"application/json"},
    body: JSON.stringify({
      model: process.env.OLLAMA_MODEL || "llama3.1:8b-instruct",
      prompt, stream: false,
      options: { temperature: 0.2 },
    }),
  });
  const data = await r.json();
  return data.response as string;
}

export async function POST(req: NextRequest) {
  const { query, k = 6, localOnly = true } = await req.json();
  if (!query) return NextResponse.json({ error: "ChybÃ­ dotaz" }, { status: 400 });

  const { embedTexts } = await import("@/lib/localEmbeddings");
  const [qvec] = await embedTexts([query]);

  const index = await loadIndex();
  const items = index?.items ?? [];
  const vectorPassages = topK(qvec, items, Number(k) || 6);
  const keywordPassages = keywordSearch(query, items, 3);
  const merged = [...vectorPassages];
  for (const candidate of keywordPassages) {
    if (!merged.find((p) => p.id === candidate.id)) merged.push(candidate);
  }
  const passages = merged.slice(0, Number(k) || 6);
  if (!passages.length) {
    return NextResponse.json({ answer: "Kontaktâ€¦", citations: [], cost: { ... } });
  }

  const context = passages.map((p,i)=>`[#${i+1}] ${p.file}\n---\n${p.content}`).join("\n\n");
  const sys = "OdpovÃ­dej pouze z kontextuâ€¦";
  const prompt = `${sys}\n\nQuestion: ${query}\n\nContext:\n${context}`;

  const maxScore = vectorPassages[0]?.score ?? 0;
  if (maxScore < 0.28 && !localOnly && process.env.OPENAI_API_KEY) {
    const chat = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      temperature: 0.2,
      messages: [
        { role: "system", content: sys },
        { role: "user", content: prompt },
      ],
    });
    return NextResponse.json({
      answer: chat.choices[0].message.content,
      citations: passages.map((p,i)=>({ id:i+1, file:p.file, idx:p.idx, score:p.score })),
    });
  }

  const answer = localOnly
    ? await generateLocal(prompt)
    : (await openai.chat.completions.create({
        model: "gpt-4o-mini",
        temperature: 0.2,
        messages: [{ role: "system", content: sys }, { role: "user", content: prompt }],
      })).choices[0].message.content ?? "";

  return NextResponse.json({
    answer,
    citations: passages.map((p,i)=>({ id:i+1, file:p.file, idx:p.idx, score:p.score })),
  });
}
```

## ğŸ–¥ï¸ UI s Markdown renderingem (`app/page.tsx`)

```tsx
"use client";
import { useState } from "react";
import ReactMarkdown from "react-markdown";
import remarkGfm from "remark-gfm";

export default function Page() {
  const [q, setQ] = useState("");
  const [msgs, setMsgs] = useState<{ q: string; a: string; c: any[] }[]>([]);

  async function ask() {
    const r = await fetch("/api/ask", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ query: q, localOnly: false }),
    });
    const data = await r.json();
    setMsgs((m) => [...m, { q, a: data.answer, c: data.citations }]);
    setQ("");
  }

  return (
    <main
      style={{ maxWidth: 800, margin: "40px auto", fontFamily: "system-ui" }}
    >
      <h1>Local Docs Chat</h1>
      <div style={{ display: "flex", gap: 8 }}>
        <input
          value={q}
          onChange={(e) => setQ(e.target.value)}
          onKeyDown={(e) => e.key === "Enter" && ask()}
          placeholder="Ask your docs..."
          style={{ flex: 1, padding: 10, border: "1px solid #ccc" }}
        />
        <button onClick={ask}>Ask</button>
      </div>
      <div style={{ marginTop: 24 }}>
        {msgs.map((m, i) => (
          <div
            key={i}
            style={{ border: "1px solid #eee", padding: 12, margin: "12px 0" }}
          >
            <div>
              <strong>You:</strong> {m.q}
            </div>
            <div style={{ marginTop: 8 }}>
              <strong>Answer:</strong>
              <ReactMarkdown remarkPlugins={[remarkGfm]}>{m.a}</ReactMarkdown>
            </div>
            {m.c?.length ? (
              <div style={{ fontSize: 14, color: "#555", marginTop: 8 }}>
                Sources: {m.c.map((c: any) => `[#${c.id} ${c.file}]`).join(" ")}
              </div>
            ) : null}
          </div>
        ))}
      </div>
    </main>
  );
}
```

**Instalace zÃ¡vislostÃ­ pro markdown:**

```bash
npm install react-markdown remark-gfm
```

## â–¶ï¸ SpuÅ¡tÄ›nÃ­

```bash
npm run dev
```

Synchronizace dokumentace:

```bash
curl -X POST -H "x-admin-key: $ADMIN_KEY" http://localhost:3000/api/admin/sync
```

Reindex (volitelnÄ› i se sync):

```bash
curl -X POST -H "x-admin-key: $ADMIN_KEY" "http://localhost:3000/api/admin/reindex?sync=1"
```

Po reindexaci se cache v pamÄ›ti automaticky invaliduje, takÅ¾e dalÅ¡Ã­ dotazy hned Ätou novÃ½ `index.json`.

Dotaz:

```bash
curl -X POST http://localhost:3000/api/ask \
  -H "Content-Type: application/json" \
  -d '{ "query": "How do I reset my password?" }'
```

## ğŸŒ VeÅ™ejnÃ© API

Endpoint `/api/ask` podporuje dva reÅ¾imy:

1. **InternÃ­ reÅ¾im** (bez autentizace): PouÅ¾Ã­vÃ¡ se pro frontend aplikaci
2. **VeÅ™ejnÃ© API reÅ¾im** (s autentizacÃ­): Pro externÃ­ integrace

### Autentizace (pouze pro veÅ™ejnÃ© API)

Pro pouÅ¾itÃ­ veÅ™ejnÃ©ho API je potÅ™eba autentizace pomocÃ­ secret key, kterÃ½ se pÅ™edÃ¡vÃ¡ v hlaviÄce:

- **HlaviÄka**: `x-api-key` nebo `Authorization: Bearer <key>`
- **PromÄ›nnÃ¡ prostÅ™edÃ­**: `PUBLIC_API_KEY` (nastav v `.env.local`)

### Rate Limiting

API je chrÃ¡nÄ›no proti zneuÅ¾itÃ­ pomocÃ­ rate limitingu:
- **Limit**: VÃ½chozÃ­ hodnota je 20 poÅ¾adavkÅ¯ za 10 minut (nastavitelnÃ© pÅ™es `RATE_LIMIT_MAX_REQUESTS`)
- **Okno**: 10 minut (fixnÃ­)
- **Identifikace**: Podle IP adresy klienta
- **HlaviÄky**: API vracÃ­ informace o rate limitu v hlaviÄkÃ¡ch:
  - `X-RateLimit-Limit`: MaximÃ¡lnÃ­ poÄet poÅ¾adavkÅ¯
  - `X-RateLimit-Remaining`: ZbÃ½vajÃ­cÃ­ poÄet poÅ¾adavkÅ¯
  - `X-RateLimit-Reset`: Unix timestamp, kdy se limit resetuje
  - `Retry-After`: PoÄet sekund do resetu (pÅ™i pÅ™ekroÄenÃ­ limitu)

### PÅ™Ã­klad pouÅ¾itÃ­

```bash
curl -X POST https://esports-chatbot.vercel.app/api/ask \
  -H "Content-Type: application/json" \
  -H "x-api-key: your_secret_key_here" \
  -d '{
    "query": "Jak resetovat heslo?",
    "websiteUrl": "https://example.com",
    "k": 6,
    "localOnly": false
  }'
```

### Parametry

**PovinnÃ©:**
- `query` (string): Dotaz uÅ¾ivatele
- `websiteUrl` (string): URL webu, na kterÃ©m API bÄ›Å¾Ã­ (pouÅ¾Ã­vÃ¡ se pro validaci a tracking)

**VolitelnÃ©:**
- `k` (number, vÃ½chozÃ­: 6): PoÄet relevantnÃ­ch pasÃ¡Å¾Ã­ k vrÃ¡cenÃ­
- `localOnly` (boolean, vÃ½chozÃ­: true): PouÅ¾Ã­t pouze lokÃ¡lnÃ­ LLM (Ollama), nebo povolit fallback na cloudovÃ½ model
- `includeCitations` (boolean, vÃ½chozÃ­: false): Zahrnout citations do odpovÄ›di (frontend automaticky posÃ­lÃ¡ `true`)

### OdpovÄ›Ä

```json
{
  "answer": "OdpovÄ›Ä na dotaz...",
  "citations": [
    {
      "id": 1,
      "file": "docs/faq.md",
      "idx": 0,
      "score": 0.85
    }
  ],
  "cost": {
    "usd": 0.0001,
    "tokens": {
      "prompt": 150,
      "completion": 50,
      "total": 200
    }
  }
}
```

### ChybovÃ© odpovÄ›di

**401 Unauthorized** - NeplatnÃ½ nebo chybÄ›jÃ­cÃ­ API klÃ­Ä:
```json
{
  "error": "Unauthorized",
  "message": "NeplatnÃ½ nebo chybÄ›jÃ­cÃ­ API klÃ­Ä"
}
```

**400 Bad Request** - ChybÄ›jÃ­cÃ­ nebo neplatnÃ© parametry:
```json
{
  "error": "Bad Request",
  "message": "ChybÃ­ povinnÃ½ parametr websiteUrl"
}
```

**429 Too Many Requests** - PÅ™ekroÄen rate limit:
```json
{
  "error": "Too Many Requests",
  "message": "PÅ™ekroÄen limit poÅ¾adavkÅ¯. MaximÃ¡lnÄ› 20 zprÃ¡v za 10 minut.",
  "resetAt": "2024-01-01T12:00:00.000Z"
}
```

### NastavenÃ­ promÄ›nnÃ½ch prostÅ™edÃ­

PÅ™idej do `.env.local`:

```env
# VeÅ™ejnÃ© API
PUBLIC_API_KEY=your_secret_key_here

# Rate limiting (volitelnÃ©, vÃ½chozÃ­: 20)
RATE_LIMIT_MAX_REQUESTS=20
```

### âš ï¸ Rate Limiting na Vercelu

**AktuÃ¡lnÃ­ implementace pouÅ¾Ã­vÃ¡ in-memory storage**, coÅ¾ mÃ¡ na Vercelu tyto limity:

1. **Serverless funkce**: KaÅ¾dÃ½ request mÅ¯Å¾e bÄ›Å¾et na jinÃ© instanci â†’ data se resetujÃ­
2. **Deploy/Restart**: PÅ™i kaÅ¾dÃ©m deploy se pamÄ›Å¥ vymaÅ¾e â†’ limity se resetujÃ­
3. **Cold starts**: NovÃ¡ instance = prÃ¡zdnÃ¡ pamÄ›Å¥

**Å˜eÅ¡enÃ­ pro produkci:**

Pro spolehlivÃ½ rate limiting na Vercelu pouÅ¾ij **Vercel KV** (key-value store):

1. VytvoÅ™ KV store v [Vercel Dashboard](https://vercel.com/dashboard)
2. Nainstaluj balÃ­Äek: `npm install @vercel/kv`
3. PÅ™idej promÄ›nnÃ© prostÅ™edÃ­:
   ```env
   KV_REST_API_URL=your_kv_url
   KV_REST_API_TOKEN=your_kv_token
   ```
4. PouÅ¾ij `lib/rateLimitKV.ts.example` jako zÃ¡klad (pÅ™ejmenuj na `rateLimitKV.ts`)

AlternativnÄ› mÅ¯Å¾eÅ¡ pouÅ¾Ã­t **Vercel Edge Middleware** s KV pro jeÅ¡tÄ› lepÅ¡Ã­ vÃ½kon.

**AktuÃ¡lnÃ­ identifikace:**
- Kombinace IP adresy + User-Agent hash
- LepÅ¡Ã­ neÅ¾ jen IP (snÃ­Å¾Ã­ problÃ©m se sdÃ­lenÃ½mi IP za NAT/proxy)
- Pro jeÅ¡tÄ› lepÅ¡Ã­ identifikaci pouÅ¾ij session cookie nebo user ID

### JavaScript/TypeScript pÅ™Ã­klad

```typescript
async function askChatbot(query: string, websiteUrl: string) {
  const response = await fetch('https://esports-chatbot.vercel.app/api/ask', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': 'your_secret_key_here',
    },
    body: JSON.stringify({
      query,
      websiteUrl,
      k: 6,
      localOnly: false,
    }),
  });

  if (!response.ok) {
    if (response.status === 429) {
      const retryAfter = response.headers.get('Retry-After');
      throw new Error(`Rate limit exceeded. Retry after ${retryAfter} seconds.`);
    }
    const error = await response.json();
    throw new Error(error.message || 'API request failed');
  }

  const data = await response.json();
  return data;
}

// PouÅ¾itÃ­
try {
  const result = await askChatbot('Jak resetovat heslo?', 'https://example.com');
  console.log(result.answer);
  console.log('Citace:', result.citations);
} catch (error) {
  console.error('Chyba:', error);
}
```

## ğŸ§± VolitelnÄ›: LokÃ¡lnÃ­ LLM pÅ™es Ollamu

1. Nainstaluj Ollamu (macOS/Linux/Win): https://ollama.com
2. StÃ¡hni model:
   ```bash
   ollama pull llama3.1:8b-instruct
   ```
3. SpusÅ¥ server: `ollama serve`
4. V `.env.local` nastav `OLLAMA_MODEL=llama3.1:8b-instruct`

`/api/ask` pouÅ¾ije Ollamu, pokud `localOnly: true` (vÃ½chozÃ­).

## ğŸ” HybridnÃ­ reÅ¾im (lokÃ¡lnÄ› + cloud)

- Embeddingy zÅ¯stÃ¡vajÃ­ lokÃ¡lnÃ­.
- GenerovÃ¡nÃ­ mÅ¯Å¾e spadnout do cloudu (levnÃ½ model) jen kdyÅ¾ je potÅ™eba.
- PoÅ¡li `localOnly: false` v tÄ›le `/api/ask`, pÅ™Ã­padnÄ› vyuÅ¾ij prah hodnoty relevance (`maxScore`).
- Cena je na malÃ©m provozu v Å™Ã¡du centÅ¯ za mÄ›sÃ­c.

## ğŸ”’ BezpeÄnost

- Admin trasy chraÅˆ pÅ™es `x-admin-key` + ideÃ¡lnÄ› IP whitelist v reverznÃ­ proxy (Caddy/Nginx).
- SloÅ¾ku `docs/` mÄ›j na perzistentnÃ­m disku (je v `.gitignore`).

## ğŸ› ï¸ NasazenÃ­

- Server s Node 20+ za HTTPS proxy (Caddy/Nginx).
- Dbej na to, aby `docs/` pÅ™eÅ¾ila redeploy (volume/bind mount).
- Systemd (volitelnÃ©): `npm run build && npm start` pod sluÅ¾bou.
- PrvnÃ­ bÄ›h embeddingu stÃ¡hne model `@xenova/transformers` (poÄÃ­tej s tÃ­m).

## ğŸ§ª OdstraÅˆovÃ¡nÃ­ potÃ­Å¾Ã­

- **Å½Ã¡dnÃ© markdowny**: pÅ™idej manifest `<tvÅ¯j_koren>/index.json` pro kaÅ¾dÃ½ z koÅ™enÅ¯ v `DOCS_BASE_URLS`.
- **PrvnÃ­ reindex je pomalÃ½**: stahuje se model, pak uÅ¾ to bÄ›Å¾Ã­ rychle.
- **Halucinace**: sniÅ¾ `k` (tÅ™eba na 4), zpÅ™Ã­sni systÃ©movÃ½ prompt, kontroluj dÄ›lenÃ­ na bloky.
- **LokÃ¡lnÃ­ LLM je pomalÃ©**: zvol menÅ¡Ã­ model (napÅ™. `mistral:7b`) nebo hybridnÃ­ reÅ¾im.

## ğŸ“ DimenzovÃ¡nÃ­

- ~20 stran A4 (~12â€“16k tokenÅ¯) â†’ po rozdÄ›lenÃ­ vyjde 20â€“40 chunkÅ¯.
- LokÃ¡lnÃ­ hledÃ¡nÃ­ je okamÅ¾itÃ©, index mÃ¡ stovky kB, nepotÅ™ebujeÅ¡ externÃ­ vektorovou DB.

## ğŸ”„ VylepÅ¡enÃ­ a zmÄ›ny

### VylepÅ¡enÃ© dÄ›lenÃ­ textu (2024-11)

- âœ… **AdaptivnÃ­ zpracovÃ¡nÃ­ dokumentÅ¯**: Funkce `splitMarkdownToChunks` automaticky detekuje typ dokumentu:
  - **Markdown s headingy**: VÄ›tÅ¡Ã­ chunky (800 tokenÅ¯), protoÅ¾e headingy poskytujÃ­ strukturu a kontext
  - **ProstÃ½ text**: MenÅ¡Ã­ chunky (300 tokenÅ¯) pro lepÅ¡Ã­ granularitu, rozdÄ›lenÃ­ podle odstavcÅ¯
- âœ… **UniverzÃ¡lnÃ­ kompatibilita**: Funguje s klasickÃ½mi MD soubory i prostÃ½mi textovÃ½mi soubory bez formÃ¡tovÃ¡nÃ­
- âœ… **OpravenÃ© embedovÃ¡nÃ­ v batch**: Funkce `embedTexts` nynÃ­ sprÃ¡vnÄ› zpracovÃ¡vÃ¡ vÃ­ce textÅ¯ najednou (dÅ™Ã­ve vrÃ¡tila jen 1 vektor pro vÅ¡echny texty)
- âœ… **PomocnÃ½ skript**: PÅ™idÃ¡n `scripts/reindex-docs.ts` pro snadnou reindexaci dokumentÅ¯

### Markdown rendering v UI (2024-11)

- âœ… **AutomatickÃ© renderovÃ¡nÃ­ markdownu**: OdpovÄ›di se nynÃ­ zobrazujÃ­ s formÃ¡tovÃ¡nÃ­m namÃ­sto surovÃ©ho markdownu
- âœ… **Podpora pro**:
  - **TuÄnÃ½ text** a _kurzÃ­va_
  - [Odkazy](https://example.com)
  - `Inline kÃ³d` a bloky kÃ³du
  - Seznamy (odrÃ¡Å¾kovÃ© i ÄÃ­slovanÃ©)
  - > Citace
  - Nadpisy (h1, h2, h3)
  - Tabulky (GitHub Flavored Markdown)
- âœ… **PÄ›knÃ© styling**: Markdown elementy jsou stylovanÃ© v souladu s designem UI (oranÅ¾ovÃ© akcenty pro odkazy a tuÄnÃ½ text)

## ğŸ”Œ VloÅ¾enÃ­ widgetu na jinÃ© weby

Chat mÅ¯Å¾eÅ¡ novÄ› vloÅ¾it jako plovoucÃ­ FAB tlaÄÃ­tko s rozbalovacÃ­m panelem:

```html
<script
  src="https://tvoje-domena.cz/embed/widget.js"
  data-title="Pomoc s dokumentacÃ­"
  data-subtitle="Chat, kterÃ½ ÄerpÃ¡ jen z naÅ¡ich zdrojÅ¯"
  data-color="#ff6200"
  data-label="Zeptej se"
  async
></script>
```

- Skript vytvoÅ™Ã­ kruhovÃ© tlaÄÃ­tko v pravÃ©m (nebo levÃ©m) dolnÃ­m rohu, kterÃ© otevÅ™e iframe s aplikacÃ­ na adrese `/embed/panel`.
- VÅ¡e bÄ›Å¾Ã­ na stejnÃ© domÃ©nÄ›, takÅ¾e nenÃ­ potÅ™eba Å™eÅ¡it CORS ani dalÅ¡Ã­ backend zmÄ›ny.
- Panel je responzivnÃ­ (max Å¡Ã­Å™ka/vÃ½Å¡ka podle viewportu) a zachovÃ¡vÃ¡ stejnÃ© funkce jako hlavnÃ­ UI, vÄetnÄ› citacÃ­ a markdown renderingu.

### DostupnÃ© atributy

- `data-title` / `data-subtitle` â€“ texty v zÃ¡hlavÃ­ panelu.
- `data-color` â€“ primÃ¡rnÃ­ barva (dotkne se FAB tlaÄÃ­tka i widgetu, zÃ¡roveÅˆ se propÃ­Å¡e do query parametru `accent`).
- `data-label` â€“ text ve FAB tlaÄÃ­tku, `data-icon` pro emoji/znak vedle textu.
- `data-position` â€“ `"left"` nebo `"right"` (vÃ½chozÃ­).
- `data-width` / `data-height` â€“ rozmÄ›r panelu (napÅ™. `data-width="420px"`).
- `data-offset`, pÅ™Ã­padnÄ› `data-offset-x` a `data-offset-y` â€“ odsazenÃ­ od okrajÅ¯ strÃ¡nky.
- `data-panel-url` â€“ pokud chceÅ¡ naÄÃ­st jinou adresu (napÅ™. proxy nebo jinou jazykovou mutaci). MusÃ­ jÃ­t o URL hostovanÃ© na stejnÃ© domÃ©nÄ› kvÅ¯li pÅ™Ã­stupu na API.

ChceÅ¡-li widget vloÅ¾it ruÄnÄ› do vlastnÃ­ komponenty, mÅ¯Å¾eÅ¡ pouÅ¾Ã­t rovnou iframe:

```html
<iframe
  src="https://tvoje-domena.cz/embed/panel?accent=%23ff6200&title=Support%20Bot"
  width="360"
  height="520"
  style="border:0;border-radius:20px;box-shadow:0 30px 60px rgba(5,6,8,0.45)"
></iframe>
```

Interakce mÅ¯Å¾eÅ¡ ovlÃ¡dat vlastnÃ­m kÃ³dem:

- `window.postMessage({ type: "esports-chat-open" }, "*")` â€” otevÅ™e panel.
- `window.postMessage({ type: "esports-chat-close" }, "*")` â€” zavÅ™e panel.
- `window.postMessage({ type: "esports-chat-toggle" }, "*")` â€” pÅ™epne stav.
- Nebo pÅ™Ã­mo `window.esportsChatWidget?.open()/close()/toggle()`.

### Jak reindexovat dokumenty

```bash
# PomocÃ­ skriptu (doporuÄeno)
npx tsx scripts/reindex-docs.ts

# Nebo pomocÃ­ API
curl -X POST -H "x-admin-key: $ADMIN_KEY" "http://localhost:3000/api/admin/reindex"
```

## âœ… Co mÃ¡ agent udÄ›lat

- VytvoÅ™it soubory podle README.
- Nainstalovat zÃ¡vislosti a nastavit `.env.local`.
- Implementovat endpointy a knihovny.
- Spustit dev server a ovÄ›Å™it:
  - `POST /api/admin/sync` stahuje `.md` soubory
  - `POST /api/admin/reindex` vytvÃ¡Å™Ã­ `docs/index.json`
  - `POST /api/ask` vracÃ­ struÄnÃ© odpovÄ›di s citacemi

Hotovo. ZkopÃ­ruj tento README do Cursoru, nech Agenta projekt vystavÄ›t, doplÅˆ `DOCS_BASE_URLS` (nebo `DOCS_BASE_URL`), spusÅ¥ sync â†’ reindex â†’ otÃ¡zka a mÃ¡Å¡ lokÃ¡lnÃ­, levnÃ½ chatbot nad dokumentacÃ­.
